download_url: https://gluebenchmark.com/
name: GLUE
papers: "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"
supporter:
  - Alex Wang
  - Amanpreet Singh
  - Julian Michael
  - Felix Hill
  - Omer Levy
  - Samuel R. Bowman
task:
  - Nature Language Understanding
description: "GLUE is centered on nine Englist sentence understanding tasks, which cover a broad range of domains, data quantitites and difficulties. 
A widely-used natural language understanding technology should process language in a way that is not exclusive to a single task.
Thus the General Language Understanding Evaluation(GLUE) benchmark, a collection of tools for evaluating the performance of models across a diverse set of existing NLU task, is developed."
# GLUE由九个不同英语句子理解任务组成，涵盖了广泛的领域、数据量和困难。由于GLUE的目标是促进可推广的NLU系统的开发，因此我们设计了一个基准，模型需要在任务间共享大量的知识，从而在不同任务上收获良好的性能。
update_time: 2018
logo_file:
